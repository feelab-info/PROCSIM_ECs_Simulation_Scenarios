{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a4efd9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install Procsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df53121",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install procsimulator==0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdda8d5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ae434e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import procsimulator\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ortools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9900b191",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from procsimulator.CommunityGenerator import CommunityGenerator\n",
    "from procsimulator.ConsumptionGenerator import ConsumptionGenerator\n",
    "from procsimulator.DataFromSmile import DataFromSmile\n",
    "from procsimulator.DataFromTomorrow import DataFromTomorrow\n",
    "from procsimulator.RenewableEnergyGenerator import RenewableEnergyGenerator\n",
    "from procsimulator.CommunityGenerator import CommunityGenerator\n",
    "from procsimulator.Evaluation import Evaluation\n",
    "from procsimulator.CommunityManagerStrategy import CommunityManagerStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db12e140",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get current path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056edc1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuno.Velosa.CORP\\OneDrive - Unipartner IT Services, S.A\\Desktop\\pyomo_experiments\\second_paper\n"
     ]
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de4bb5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generation of the consumption profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c83cac76",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_steps_seconds = os.path.join(current_path, \"..\")\n",
    "path_steps_minutes = \"../output/minute\"\n",
    "path_steps_after_first = \"../output/afterfirstoptimization\"\n",
    "path_steps_after_second = \"../output/aftersecondoptimization\"\n",
    "num_days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ee8887",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cg = ConsumptionGenerator(\"../data.json\", path_steps_seconds, path_steps_minutes)\n",
    "#cg.execute(num_days, \"houses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7afac3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../output/afterfirstoptimization/community.csv\n",
      "../output/afterfirstoptimization/community_baseload.csv\n",
      "../output/afterfirstoptimization/community_not_baseload.csv\n",
      "../output/afterfirstoptimization/energy.csv\n",
      "../output/afterfirstoptimization/house0\n",
      "../output/afterfirstoptimization/house1\n",
      "../output/afterfirstoptimization/house2\n",
      "../output/afterfirstoptimization/house3\n",
      "../output/afterfirstoptimization/house4\n",
      "../output/afterfirstoptimization/netload.csv\n",
      "\n",
      "../output/aftersecondoptimization/community.csv\n",
      "../output/aftersecondoptimization/community_baseload.csv\n",
      "../output/aftersecondoptimization/community_not_baseload.csv\n",
      "../output/aftersecondoptimization/energy.csv\n",
      "../output/aftersecondoptimization/house0\n",
      "../output/aftersecondoptimization/house1\n",
      "../output/aftersecondoptimization/house2\n",
      "../output/aftersecondoptimization/house3\n",
      "../output/aftersecondoptimization/house4\n",
      "../output/aftersecondoptimization/netload.csv\n",
      "\n",
      "../output/house0/AMPLIFIER.csv\n",
      "../output/house0/Ann.csv\n",
      "../output/house0/baseload.csv\n",
      "../output/house0/BREADCUTTER.csv\n",
      "../output/house0/CDPLAYER.csv\n",
      "../output/house0/COFFEEMAKER.csv\n",
      "../output/house0/COOKINGSTOVE.csv\n",
      "../output/house0/cooking_a_dinner.csv\n",
      "../output/house0/DISHWASHER.csv\n",
      "../output/house0/DRYER.csv\n",
      "../output/house0/events.csv\n",
      "../output/house0/FREEZER.csv\n",
      "../output/house0/fridge_operation.csv\n",
      "../output/house0/IRON.csv\n",
      "../output/house0/KETTLE.csv\n",
      "../output/house0/listen_to_a_74_minute_audio_CD.csv\n",
      "../output/house0/MICROWAVE.csv\n",
      "../output/house0/microwaving_food.csv\n",
      "../output/house0/PC.csv\n",
      "../output/house0/preparing_breakfast_with_coffee_or_tea_and_toast_or_eggs.csv\n",
      "../output/house0/PRINTER.csv\n",
      "../output/house0/REFRIGERATOR.csv\n",
      "../output/house0/TOASTER.csv\n",
      "../output/house0/total.csv\n",
      "../output/house0/TV.csv\n",
      "../output/house0/use_a_personal_computer.csv\n",
      "../output/house0/VACUUMCLEANER.csv\n",
      "../output/house0/vacuuming.csv\n",
      "../output/house0/WASHINGMACHINE.csv\n",
      "../output/house0/washing_a_load_of_laundry.csv\n",
      "../output/house0/watching_TV.csv\n",
      "\n",
      "../output/house1/AMPLIFIER.csv\n",
      "../output/house1/Ann.csv\n",
      "../output/house1/baseload.csv\n",
      "../output/house1/BREADCUTTER.csv\n",
      "../output/house1/CDPLAYER.csv\n",
      "../output/house1/COFFEEMAKER.csv\n",
      "../output/house1/COOKINGSTOVE.csv\n",
      "../output/house1/cooking_a_dinner.csv\n",
      "../output/house1/DISHWASHER.csv\n",
      "../output/house1/DRYER.csv\n",
      "../output/house1/events.csv\n",
      "../output/house1/FREEZER.csv\n",
      "../output/house1/fridge_operation.csv\n",
      "../output/house1/IRON.csv\n",
      "../output/house1/KETTLE.csv\n",
      "../output/house1/listen_to_a_74_minute_audio_CD.csv\n",
      "../output/house1/MICROWAVE.csv\n",
      "../output/house1/microwaving_food.csv\n",
      "../output/house1/PC.csv\n",
      "../output/house1/preparing_breakfast_with_coffee_or_tea_and_toast_or_eggs.csv\n",
      "../output/house1/PRINTER.csv\n",
      "../output/house1/REFRIGERATOR.csv\n",
      "../output/house1/TOASTER.csv\n",
      "../output/house1/total.csv\n",
      "../output/house1/TV.csv\n",
      "../output/house1/use_a_personal_computer.csv\n",
      "../output/house1/VACUUMCLEANER.csv\n",
      "../output/house1/vacuuming.csv\n",
      "../output/house1/WASHINGMACHINE.csv\n",
      "../output/house1/washing_a_load_of_laundry.csv\n",
      "../output/house1/watching_TV.csv\n",
      "\n",
      "../output/house2/AMPLIFIER.csv\n",
      "../output/house2/Ann.csv\n",
      "../output/house2/baseload.csv\n",
      "../output/house2/Bill.csv\n",
      "../output/house2/BREADCUTTER.csv\n",
      "../output/house2/CDPLAYER.csv\n",
      "../output/house2/COFFEEMAKER.csv\n",
      "../output/house2/COOKINGSTOVE.csv\n",
      "../output/house2/cooking_a_dinner.csv\n",
      "../output/house2/DISHWASHER.csv\n",
      "../output/house2/DRYER.csv\n",
      "../output/house2/events.csv\n",
      "../output/house2/FREEZER.csv\n",
      "../output/house2/fridge_operation.csv\n",
      "../output/house2/IRON.csv\n",
      "../output/house2/KETTLE.csv\n",
      "../output/house2/listen_to_a_74_minute_audio_CD.csv\n",
      "../output/house2/MICROWAVE.csv\n",
      "../output/house2/microwaving_food.csv\n",
      "../output/house2/PC.csv\n",
      "../output/house2/preparing_breakfast_with_coffee_or_tea_and_toast_or_eggs.csv\n",
      "../output/house2/PRINTER.csv\n",
      "../output/house2/REFRIGERATOR.csv\n",
      "../output/house2/TOASTER.csv\n",
      "../output/house2/total.csv\n",
      "../output/house2/TV.csv\n",
      "../output/house2/use_a_personal_computer.csv\n",
      "../output/house2/VACUUMCLEANER.csv\n",
      "../output/house2/vacuuming.csv\n",
      "../output/house2/WASHINGMACHINE.csv\n",
      "../output/house2/washing_a_load_of_laundry.csv\n",
      "../output/house2/watching_TV.csv\n",
      "\n",
      "../output/house3/AMPLIFIER.csv\n",
      "../output/house3/Ann.csv\n",
      "../output/house3/baseload.csv\n",
      "../output/house3/Bill.csv\n",
      "../output/house3/BREADCUTTER.csv\n",
      "../output/house3/CDPLAYER.csv\n",
      "../output/house3/COFFEEMAKER.csv\n",
      "../output/house3/COOKINGSTOVE.csv\n",
      "../output/house3/cooking_a_dinner.csv\n",
      "../output/house3/DISHWASHER.csv\n",
      "../output/house3/dishwasher_operation.csv\n",
      "../output/house3/DRYER.csv\n",
      "../output/house3/events.csv\n",
      "../output/house3/FREEZER.csv\n",
      "../output/house3/fridge_operation.csv\n",
      "../output/house3/IRON.csv\n",
      "../output/house3/John.csv\n",
      "../output/house3/KETTLE.csv\n",
      "../output/house3/listen_to_a_74_minute_audio_CD.csv\n",
      "../output/house3/MICROWAVE.csv\n",
      "../output/house3/microwaving_food.csv\n",
      "../output/house3/PC.csv\n",
      "../output/house3/preparing_breakfast_with_coffee_or_tea_and_toast_or_eggs.csv\n",
      "../output/house3/PRINTER.csv\n",
      "../output/house3/REFRIGERATOR.csv\n",
      "../output/house3/TOASTER.csv\n",
      "../output/house3/Toby.csv\n",
      "../output/house3/total.csv\n",
      "../output/house3/TV.csv\n",
      "../output/house3/use_a_personal_computer.csv\n",
      "../output/house3/VACUUMCLEANER.csv\n",
      "../output/house3/vacuuming.csv\n",
      "../output/house3/WASHINGMACHINE.csv\n",
      "../output/house3/washing_a_load_of_laundry.csv\n",
      "../output/house3/watching_TV.csv\n",
      "\n",
      "../output/house4/AMPLIFIER.csv\n",
      "../output/house4/Ann.csv\n",
      "../output/house4/baseload.csv\n",
      "../output/house4/Bill.csv\n",
      "../output/house4/BREADCUTTER.csv\n",
      "../output/house4/CDPLAYER.csv\n",
      "../output/house4/COFFEEMAKER.csv\n",
      "../output/house4/COOKINGSTOVE.csv\n",
      "../output/house4/cooking_a_dinner.csv\n",
      "../output/house4/DISHWASHER.csv\n",
      "../output/house4/dishwasher_operation.csv\n",
      "../output/house4/DRYER.csv\n",
      "../output/house4/events.csv\n",
      "../output/house4/FREEZER.csv\n",
      "../output/house4/fridge_operation.csv\n",
      "../output/house4/IRON.csv\n",
      "../output/house4/John.csv\n",
      "../output/house4/KETTLE.csv\n",
      "../output/house4/listen_to_a_74_minute_audio_CD.csv\n",
      "../output/house4/MICROWAVE.csv\n",
      "../output/house4/microwaving_food.csv\n",
      "../output/house4/PC.csv\n",
      "../output/house4/preparing_breakfast_with_coffee_or_tea_and_toast_or_eggs.csv\n",
      "../output/house4/PRINTER.csv\n",
      "../output/house4/REFRIGERATOR.csv\n",
      "../output/house4/TOASTER.csv\n",
      "../output/house4/total.csv\n",
      "../output/house4/TV.csv\n",
      "../output/house4/use_a_personal_computer.csv\n",
      "../output/house4/VACUUMCLEANER.csv\n",
      "../output/house4/vacuuming.csv\n",
      "../output/house4/WASHINGMACHINE.csv\n",
      "../output/house4/washing_a_load_of_laundry.csv\n",
      "../output/house4/watching_TV.csv\n",
      "\n",
      "../output/minute/community.csv\n",
      "../output/minute/community_baseload.csv\n",
      "../output/minute/community_not_baseload.csv\n",
      "../output/minute/energy.csv\n",
      "../output/minute/house0\n",
      "../output/minute/house1\n",
      "../output/minute/house2\n",
      "../output/minute/house3\n",
      "../output/minute/house4\n",
      "../output/minute/netload.csv\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "path = \"../output\"\n",
    "\n",
    "def update_dataframe(path):    \n",
    "    if (\"events\" not in path):\n",
    "        df = pd.read_csv(path, sep=';')\n",
    "\n",
    "        try:\n",
    "            df[\"Date\"] = df[\"Date\"].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\") - pd.Timedelta(days=102))\n",
    "        except:\n",
    "            df.columns=['Date','Power']\n",
    "            df[\"Date\"] = df[\"Date\"].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\") - pd.Timedelta(weeks=102))\n",
    "        #print(df['Date'])\n",
    "            \n",
    "        x = path.rsplit('/', 1)\n",
    "        #print(x)\n",
    "\n",
    "        output_directory = os.path.join('', x[0])\n",
    "        outname = os.path.join(output_directory, x[1])\n",
    "        df.to_csv(outname, sep=\";\", index=False)\n",
    "\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "    print(\"\")\n",
    "    file = path + \"/\" + folder\n",
    "    for f in os.listdir(file):\n",
    "        df_path = file + \"/\" + f\n",
    "        print(df_path)\n",
    "        \n",
    "        #if (os.path.isdir(df_path)):\n",
    "            #for fm in os.listdir(df_path):\n",
    "                #update_dataframe(df_path + \"/\" + fm)\n",
    "        #else:\n",
    "            #update_dataframe(df_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675c4c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generation of PV (and Wind Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827534f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renewable Energy Generator\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'period_end'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\nuno.velosa.corp\\onedrive - unipartner it services, s.a\\desktop\\pyomo_experiments\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nuno.velosa.corp\\onedrive - unipartner it services, s.a\\desktop\\pyomo_experiments\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nuno.velosa.corp\\onedrive - unipartner it services, s.a\\desktop\\pyomo_experiments\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nuno.velosa.corp\\onedrive - unipartner it services, s.a\\desktop\\pyomo_experiments\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nuno.velosa.corp\\onedrive - unipartner it services, s.a\\desktop\\pyomo_experiments\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nuno.velosa.corp\\onedrive - unipartner it services, s.a\\desktop\\pyomo_experiments\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine._unpack_bool_indexer\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'period_end'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_5400\\2529559621.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m#reg.execute(num_days)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Renewable Energy Generator\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpv_dat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_weather_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0mresampled_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpv_dat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresample_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"1min\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mpower\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_pv_power\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresampled_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1000\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m32.756\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m17.179\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nuno.velosa.corp\\onedrive - unipartner it services, s.a\\desktop\\pyomo_experiments\\venv\\lib\\site-packages\\procsimulator\\DataFromSmile.py\u001B[0m in \u001B[0;36mget_weather_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;31m# Create subset of the dataset with just 4 columns (Start, dhi, ghi and dni)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m     \u001B[0msmile\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0msmile_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"period_end\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msmile_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"dhi\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msmile_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"ghi\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msmile_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"dni\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[0mheaders\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"Start\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"dhi\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ghi\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"dni\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nuno.velosa.corp\\onedrive - unipartner it services, s.a\\desktop\\pyomo_experiments\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3456\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3457\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3458\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3459\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3460\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\nuno.velosa.corp\\onedrive - unipartner it services, s.a\\desktop\\pyomo_experiments\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3363\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3365\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'period_end'"
     ]
    }
   ],
   "source": [
    "pv_dat = DataFromSmile(\"https://ems.prsma.com/solcast/public/Fazendinha_solcast-radiation-historical_30min.csv\")\n",
    "#wind_dat = DataFromTomorrow(\"https://api.tomorrow.io/v4/timelines?location=-73.98529171943665,40.75872069597532&fields=pressureSurfaceLevel,pressureSeaLevel,precipitationIntensity,precipitationType,windSpeed,windGust,windDirection,temperature,temperatureApparent,cloudCover,cloudBase,cloudCeiling,weatherCode&timesteps=1h&units=metric&apikey=Yckmp3vREbJqyprWGGiTOC1pVaAYO0ZT\")\n",
    "#wind_dat = DataFromTomorrow(\"https://api.tomorrow.io/v4/timelines?startTime=now&endTime=nowPlus8d&location=-73.98529171943665,40.75872069597532&fields=pressureSurfaceLevel,pressureSeaLevel,precipitationIntensity,precipitationType,windSpeed,windGust,windDirection,temperature,temperatureApparent,cloudCover,cloudBase,cloudCeiling,weatherCode&timesteps=1h&units=metric&apikey=Yckmp3vREbJqyprWGGiTOC1pVaAYO0ZT\")\n",
    "wind_dat = pd.DataFrame();\n",
    "reg = RenewableEnergyGenerator(cg, pv_dat, wind_dat, cg.path_steps_minutes)\n",
    "\n",
    "#reg.execute(num_days)\n",
    "print(\"Renewable Energy Generator\")\n",
    "data = reg.pv_dat.get_weather_data()\n",
    "resampled_data = reg.pv_dat.resample_data(data, \"1min\")\n",
    "power = reg.get_pv_power(resampled_data, 2, 1000, 32.756, -17.179)\n",
    "\n",
    "community = pd.read_csv(reg.path_steps_minutes + '/community.csv', sep=';')\n",
    "community.columns = ['Date', 'Power']\n",
    "first_date = reg.get_first_and_last_date_of_community()[0]\n",
    "last_date = reg.get_first_and_last_date_of_community()[1]\n",
    "filtered_data = reg.pv_dat.filter_data(power, first_date, last_date)\n",
    "\n",
    "# Update energy csv file\n",
    "output_directory = os.path.join('', reg.path_steps_minutes)\n",
    "outname = os.path.join(output_directory, 'energy.csv')\n",
    "filtered_data.to_csv(outname, columns=['Date', 'Power'], sep=\";\", index=False)\n",
    "\n",
    "# Set Index of Community Needs\n",
    "community = community.set_index('Date')\n",
    "community.index = pd.to_datetime(community.index)\n",
    "\n",
    "# Set Index of PV Power Forecast\n",
    "filtered_data = filtered_data.set_index('Date')\n",
    "filtered_data['Power'] = filtered_data['Power'].fillna(0)\n",
    "filtered_data.index = pd.to_datetime(filtered_data.index)\n",
    "\n",
    "energy_contracted_power = reg.cg.calculate_contracted_power(reg.cg.get_community())*0.5\n",
    "print(\"energy contracted: \" + str(energy_contracted_power))\n",
    "\n",
    "filtered_data = reg.normalize_power_dataframe(filtered_data, 220, energy_contracted_power) # Normalize dataframe and multiply by 220\n",
    "filtered_data.loc[filtered_data['Power'] < 0, 'Power'] = 0 # Remove negative power (convert it to zero)\n",
    "\n",
    "# Merges the community demand with the PV production\n",
    "production = pd.merge(community, filtered_data, on='Date')\n",
    "production = production.reset_index()\n",
    "\n",
    "# Reindex columns and renames\n",
    "production = production.reindex(columns=['Date', 'Power_y', 'Power_x'])\n",
    "production = production.rename({'Power_y': 'PV_Production', 'Power_x': 'Demand'}, axis=1) # Change column names\n",
    "\n",
    "production[\"Wind_Production\"] = 0\n",
    "production[\"Production\"] = production[\"PV_Production\"] + production[\"Wind_Production\"]\n",
    "print(production)\n",
    "    \n",
    "# Create netload csv file to store the production\n",
    "output_directory = os.path.join('', reg.path_steps_minutes)\n",
    "outname = os.path.join(output_directory, 'netload.csv')\n",
    "production.to_csv(outname, columns=['Date', 'Demand', 'PV_Production', 'Wind_Production', 'Production'], sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e9003",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calculation of netload and Generation of the EC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e1d76",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cmg = CommunityGenerator(cg.path_steps_minutes)\n",
    "cmg.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45d3f6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calculate metrics in the EC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90024185",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_steps_minutes + '/netload.csv', sep=';')\n",
    "evaluation = Evaluation(df, 0)\n",
    "\n",
    "print(\"Average Power Used from Grid: \" + \"{:.2f}\".format(evaluation.get_average_power_used_from_grid()) + \" kW\")\n",
    "print(\"Average Power Used from PV: \" + \"{:.2f}\".format(evaluation.get_average_power_used_from_pv()) + \" kW\")\n",
    "print(\"Average Power Not Used from PV: \" + \"{:.2f}\".format(evaluation.get_average_power_not_used_from_pv()) + \" kW\")\n",
    "print(\"Energy Used from Grid: \" + \"{:.2f}\".format(evaluation.get_energy_used_from_grid()) + \" kWh\")\n",
    "print(\"Energy Used from PV: \" + \"{:.2f}\".format(evaluation.get_energy_used_from_pv()) + \" kWh\")\n",
    "print(\"Energy Not Used from PV: \" + \"{:.2f}\".format(evaluation.get_energy_not_used_from_pv()) + \" kWh\")\n",
    "print(\"Peaks Number: \" + str(evaluation.get_peaks_number()))\n",
    "print(\"Self Sufficiency (SS): \" + \"{:.2f}\".format(evaluation.get_self_sufficiency()*100) + \"%\")\n",
    "print(\"Self Consumption (SC): \" + \"{:.2f}\".format(evaluation.get_self_consumption()*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e5409",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calculation of Community PPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de043bce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Getting the community contracted power\n",
    "community = cg.get_community()\n",
    "print(\"Contracted Power: \" + str(cg.calculate_contracted_power(community)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cbe5df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Knapsack with Load Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60c0c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyomo\n",
    "import pyomo.opt\n",
    "import pyomo.environ as pyo\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _auxDictionary(a):\n",
    "  temp_dictionary = {}\n",
    "  if len(a.shape) == 3:\n",
    "    for dim0 in np.arange(a.shape[0]):\n",
    "      for dim1 in np.arange(a.shape[1]):\n",
    "        for dim2 in np.arange(a.shape[2]):\n",
    "          temp_dictionary[(dim0+1, dim1+1, dim2+1)] = a[dim0, dim1, dim2]\n",
    "  elif len(a.shape) == 2:\n",
    "    for dim0 in np.arange(a.shape[0]):\n",
    "      for dim1 in np.arange(a.shape[1]):\n",
    "        temp_dictionary[(dim0+1, dim1+1)] = a[dim0, dim1]\n",
    "  else:\n",
    "    for dim0 in np.arange(a.shape[0]):\n",
    "      temp_dictionary[(dim0+1)] = a[dim0]\n",
    "  return temp_dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ext_pyomo_vals(vals):\n",
    "    # make a pd.Series from each\n",
    "    s = pd.Series(vals.extract_values(),\n",
    "                  index=vals.extract_values().keys())\n",
    "    # if the series is multi-indexed we need to unstack it...\n",
    "    if type(s.index[0]) == tuple:    # it is multi-indexed\n",
    "        s = s.unstack(level=1)\n",
    "    else:\n",
    "        # force transition from Series -> df\n",
    "        s = pd.DataFrame(s)\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class KnapsackBalancing:\n",
    "\n",
    "  def __init__(self, dates, items, bin_capacities, numbers, bins_maximum, items_maximum, baseload, fact, n_bins_per_hour, flexibilities, export_prices, import_prices, num_evs, evs_max, evs_min, initial_soc, evs_availability, efficiency, p_charger):\n",
    "    \"\"\"\n",
    "    This class receives as input some arrays with information about the timeslots and the bins, as well as some global data (baseload, fact and n_bins_per_hour)\n",
    "\n",
    "    Args:\n",
    "      dates: array containing the bin in which the user wants to place the timeslot\n",
    "      items: array containing the timeslot energy for each item of each timeslot\n",
    "      bin_capacities: array containing the bin capactity of each bin\n",
    "      numbers: array containing the number of the timeslot of each item of each timeslot\n",
    "      bins_maximum: array containing the maximum power of the production of each bin\n",
    "      items_maximum: array containing the maximum power of each item of each timeslot\n",
    "      baseload: value that represents the value of energy that can be acquired from the grid in the 2nd step\n",
    "      fact: minutes of each bin (e.g. if bins of 30 minutes, fact = 30)\n",
    "      n_bins_per_hour: number of bins per hour (parameter of the strategy) to know the quantity of bins in a day (e.g. if bins of 30 minutes, n_bins_per_hour = 2)\n",
    "      flexibilities: array contanining the flexibility of each item of each timeslot\n",
    "      energy_prices: array containing the energy prices of each bin\n",
    "    \"\"\"\n",
    "    self.dates = dates\n",
    "    self.items = items\n",
    "    self.numbers = numbers\n",
    "    self.baseload = baseload\n",
    "    self.bin_capacities = bin_capacities\n",
    "    self.bins_maximum = bins_maximum\n",
    "    self.items_maximum = items_maximum\n",
    "    self.fact = fact\n",
    "    self.n_bins_per_hour = n_bins_per_hour\n",
    "    self.num_bins = n_bins_per_hour * 24\n",
    "    self.flexibilities = flexibilities\n",
    "    self.export_prices = export_prices\n",
    "    self.import_prices = import_prices\n",
    "    self.num_evs = num_evs\n",
    "    self.maximum_soc = evs_max\n",
    "    self.minimum_soc = evs_min\n",
    "    self.initial_soc = initial_soc\n",
    "    self.availability = evs_availability\n",
    "    self.efficiency = efficiency\n",
    "    self.p_charger = p_charger\n",
    "    self.dataframes = {}\n",
    "\n",
    "\n",
    "  def create_data_model(self):\n",
    "    \"\"\"\n",
    "    Creates the data model for the Multi Knapsack problem, according to the input received in the constructor\n",
    "\n",
    "    Returns:\n",
    "      data model (list with different arrays and values)\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    data['tim_lens'] = [len(i) for i in self.items]\n",
    "    data['max_len'] = max(data['tim_lens'])\n",
    "    data['weights'] = pd.DataFrame(self.items).fillna(0)\n",
    "    data['dates'] = pd.DataFrame(self.dates).fillna(0)\n",
    "    data['numbers'] = pd.DataFrame(self.numbers).fillna(0)\n",
    "    data['items'] = list(range(len(self.items)))\n",
    "    data['num_items'] = len(self.items)\n",
    "    num_bins = len(self.bin_capacities)\n",
    "    data['bins'] = list(range(num_bins))\n",
    "    data['bin_capacities'] = pd.DataFrame(self.bin_capacities)\n",
    "    data['bins_maximum'] = pd.DataFrame(self.bins_maximum)\n",
    "    data['items_maximum'] = pd.DataFrame(self.items_maximum).fillna(0)\n",
    "    data['baseload'] = self.baseload\n",
    "    data['fact'] = self.fact\n",
    "    data['n_bins_per_hour'] = self.n_bins_per_hour\n",
    "    data['num_bins'] = self.num_bins\n",
    "    data['flexibilities'] = pd.DataFrame(self.flexibilities).fillna(0)\n",
    "    data['export_prices'] = pd.DataFrame(self.export_prices)\n",
    "    data['import_prices'] = pd.DataFrame(self.import_prices)\n",
    "    data['num_evs'] = self.num_evs\n",
    "    data['maximum_soc'] = self.maximum_soc\n",
    "    data['minimum_soc'] = self.minimum_soc\n",
    "    data['initial_soc'] = self.initial_soc\n",
    "    data['availability'] = self.availability\n",
    "    data['efficiency'] = self.efficiency\n",
    "    data['p_charger'] = self.p_charger\n",
    "    return data\n",
    "\n",
    "\n",
    "  def create_sets(self, model, data):\n",
    "\n",
    "    model.b = pyo.Set(initialize = np.arange(1, data['num_bins'] + 1))\n",
    "    model.t = pyo.Set(initialize = np.arange(1, data['num_items'] + 1))\n",
    "    model.i = pyo.Set(initialize = np.arange(1, data['max_len'] + 1))\n",
    "    model.ev = pyo.Set(initialize = np.arange(1, data['num_evs'] + 1))\n",
    "\n",
    "\n",
    "\n",
    "  def create_parameters(self, model, data):\n",
    "\n",
    "    model.tim_lens = pyo.Param(model.t, initialize = _auxDictionary(np.array(data['tim_lens'])))\n",
    "    model.weights = pyo.Param(model.t, model.i, initialize = _auxDictionary(np.array(data['weights'])))\n",
    "    model.dates = pyo.Param(model.t, model.i, initialize = _auxDictionary(np.array(data['dates'])))\n",
    "    model.numbers = pyo.Param(model.t, model.i, initialize = _auxDictionary(np.array(data['numbers'])))\n",
    "    model.bin_capacities = pyo.Param(model.b, initialize = _auxDictionary(np.array(data['bin_capacities']).ravel()))\n",
    "    model.bins_maximum = pyo.Param(model.b, initialize = _auxDictionary(np.array(data['bins_maximum']).ravel()))\n",
    "    model.items_maximum = pyo.Param(model.t, model.i, initialize = _auxDictionary(np.array(data['items_maximum'])))\n",
    "    model.baseload = pyo.Param(initialize = data['baseload'])\n",
    "    model.fact = pyo.Param(initialize = data['fact'])\n",
    "    model.n_bins_per_hour = pyo.Param(initialize = data['n_bins_per_hour'])\n",
    "    model.num_bins = pyo.Param(initialize = data['num_bins'])\n",
    "    model.flexibilities = pyo.Param(model.t, model.i, initialize = _auxDictionary(np.array(data['flexibilities'])))\n",
    "    model.export_prices = pyo.Param(model.b, initialize = _auxDictionary(np.array(data['export_prices']).ravel()))\n",
    "    model.import_prices = pyo.Param(model.b, initialize = _auxDictionary(np.array(data['import_prices']).ravel()))\n",
    "    model.ev_soc_min = pyo.Param(model.ev, initialize = _auxDictionary(np.array(data['minimum_soc'])))\n",
    "    model.ev_soc_max = pyo.Param(model.ev, initialize = _auxDictionary(np.array(data['maximum_soc'])))\n",
    "    model.ev_initial_soc = pyo.Param(model.ev, initialize = _auxDictionary(np.array(data['initial_soc'])))\n",
    "    model.availability = pyo.Param(model.b, model.ev, initialize = _auxDictionary(np.array(data['availability'].transpose())))\n",
    "    model.n = data['efficiency'] # Efficiency\n",
    "    model.p_charger = data['p_charger'] # Charging station power\n",
    "    model.M = 1000000 # Big M\n",
    "\n",
    "\n",
    "  def create_variables(self, model):\n",
    "\n",
    "    model.x = pyo.Var(model.b, model.t, model.i, domain=pyo.Binary, initialize=0)\n",
    "    model.pImp = pyo.Var(model.b, domain=pyo.NonNegativeReals, initialize=0)\n",
    "    model.pExp = pyo.Var(model.b, domain=pyo.NonNegativeReals, initialize=0)\n",
    "    model.ev_charge = pyo.Var(model.b, model.ev, domain=pyo.NonNegativeReals, initialize=0)\n",
    "    model.ev_discharge = pyo.Var(model.b, model.ev, domain=pyo.NonNegativeReals, initialize=0)\n",
    "    model.ev_soc = pyo.Var(model.b, model.ev, domain=pyo.NonNegativeReals, initialize=0)\n",
    "    model.is_importing = pyo.Var(model.b, domain=pyo.Binary, initialize=0)\n",
    "\n",
    "\n",
    "  def create_constraints(self, model, data):\n",
    "\n",
    "    # An item of a timeslot can't be in more than one bin and all items have to be placed\n",
    "    # The first condition is for those items that belongs to the timeslot\n",
    "    # THe second condition is for those items that don't belong to the timeslot\n",
    "    def _unique_bin(m,t,i):\n",
    "      if (i <= m.tim_lens[t]): # Items used\n",
    "        return sum(m.x[b,t,i] for b in m.b) == 1\n",
    "      else: # Items not used\n",
    "        return sum(m.x[b,t,i] for b in m.b) == 0\n",
    "      #return sum([m.x[k, t, i] for k in np.arange(1, data['num_bins'] + 1)]) <= 1\n",
    "    model.unique_bin = pyo.Constraint(model.t, model.i, rule = _unique_bin)\n",
    "\n",
    "\n",
    "    # All the items of the timeslots have to be placed in the bins\n",
    "    def _all_items_placed(m,t):\n",
    "      return sum([m.x[k, t, i] for i in np.arange(1, data['max_len'] + 1) for k in np.arange(1, data['num_bins'] + 1)]) == m.tim_lens[t]\n",
    "    #model.all_items_placed = pyo.Constraint(model.t, rule = _all_items_placed)\n",
    "\n",
    "\n",
    "    # A bin can't contain more than one item of a timeslot (the timeslot items can't be in the same bin)\n",
    "    def _one_item_per_bin(m, t, b):\n",
    "      return sum([m.x[b, t, i] for i in np.arange(1, data['max_len'] + 1)]) <= 1\n",
    "    model.one_item_per_bin = pyo.Constraint(model.t, model.b, rule = _one_item_per_bin)\n",
    "\n",
    "\n",
    "    # The items of a timeslot have to be placed in consecutive bins (in an ascendent order)\n",
    "    # Item 2 should be placed in the next bin of Item 1 and so on\n",
    "    # Regarding the condition b == 1, in the first bin it is not possible to have Item higher than 1 (because the previous condition is just for b > 1)\n",
    "    def _ascendent_order(m,t,i,b):\n",
    "      if (i > 1 and i <= m.tim_lens[t] and b > 1):\n",
    "        return m.x[b, t, i ] * b - m.x[b-1, t, i-1] * (b-1) <= 1\n",
    "      elif (b == 1):\n",
    "        return m.x[b, t, i] * i <= 1\n",
    "      else:\n",
    "        return pyo.Constraint.Skip\n",
    "    model.ascendent_order = pyo.Constraint(model.t, model.i, model.b, rule = _ascendent_order)\n",
    "\n",
    "\n",
    "    # The items of a timeslot have to be placed in consecutive bins (in an ascendent order)\n",
    "    # Item 2 should be placed in the next bin of Item 1 and so on\n",
    "    def _ascendent_order2(m,t,i,b):\n",
    "      if (i > 1 and i <= m.tim_lens[t] and b > 1):\n",
    "        return m.x[b, t, i ] * b - m.x[b-1, t, i-1] * (b-1) >= 0\n",
    "      else:\n",
    "        return pyo.Constraint.Skip\n",
    "    model.ascendent_order2 = pyo.Constraint(model.t, model.i, model.b, rule = _ascendent_order2)\n",
    "\n",
    "\n",
    "\n",
    "    # The items of a timeslot have to be placed in consecutive bins (in a descendent order)\n",
    "    # Item 1 should be placed in the previous bin of Item 2 and so on\n",
    "    def _descendent_order(m,t,i,b):\n",
    "      if (i < m.tim_lens[t] and m.tim_lens[t] > 1 and b < m.num_bins):\n",
    "        return m.x[b+1, t, i+1] * (b+1) - m.x[b, t, i] * b <= 1\n",
    "      else:\n",
    "        return pyo.Constraint.Skip\n",
    "    model.descendent_order = pyo.Constraint(model.t, model.i, model.b, rule = _descendent_order)\n",
    "\n",
    "\n",
    "\n",
    "    # The items of a timeslot have to be placed in consecutive bins (in a descendent order)\n",
    "    # Item 1 should be placed in the previous bin of Item 2 and so on\n",
    "    def _descendent_order2(m,t,i,b):\n",
    "      if (i < m.tim_lens[t] and m.tim_lens[t] > 1 and b < m.num_bins):\n",
    "        return m.x[b+1, t, i+1] - m.x[b, t, i] >= 0\n",
    "      else:\n",
    "        return pyo.Constraint.Skip\n",
    "    model.descendent_order2 = pyo.Constraint(model.t, model.i, model.b, rule = _descendent_order2)\n",
    "\n",
    "\n",
    "\n",
    "    # The house and appliance flexibilities have to be respected (min limit)\n",
    "    def _flexibility_max(m,t,i,b):\n",
    "      if (i <= m.tim_lens[t]):\n",
    "        #diff = b - m.dates[t,i]\n",
    "        #return m.x[b, t, i] * diff >= -1 * m.flexibilities[t,i] * m.n_bins_per_hour\n",
    "        return m.x[b, t, i] * b - m.x[b, t, i] * m.dates[t,i] >= -1 * m.flexibilities[t,i] * m.n_bins_per_hour\n",
    "      else:\n",
    "        return pyo.Constraint.Skip\n",
    "    model.flexibility_max = pyo.Constraint(model.t, model.i, model.b, rule = _flexibility_max)\n",
    "\n",
    "\n",
    "    # The house and appliance flexibilities have to be respected (max limit)\n",
    "    def _flexibility_min(m,t,i,b):\n",
    "      if (i <= m.tim_lens[t]):\n",
    "        return m.x[b, t, i] * b - m.x[b, t, i] * m.dates[t,i] <= m.flexibilities[t,i] * m.n_bins_per_hour\n",
    "      else:\n",
    "        return pyo.Constraint.Skip\n",
    "    model.flexibility_min = pyo.Constraint(model.t, model.i, model.b, rule = _flexibility_min)\n",
    "\n",
    "\n",
    "    # Balance of the Load\n",
    "    def _balance(m,b):\n",
    "      return sum(m.weights[t,i] * m.x[b, t, i] for t in m.t for i in m.i if i <= m.tim_lens[t]) + m.pExp[b] + sum(m.ev_charge[b, ev]*m.n for ev in m.ev) == m.bin_capacities[b] + m.pImp[b] + sum(m.ev_discharge[b, ev]/m.n for ev in m.ev)\n",
    "    model.balance = pyo.Constraint(model.b, rule = _balance)\n",
    "\n",
    "\n",
    "    # Calculation of the EV SOC\n",
    "    def _soc_ev(m,b,ev):\n",
    "      if (b == 1):\n",
    "        return m.ev_soc[b,ev] == m.ev_soc_min[ev] + m.ev_charge[b,ev]*m.n - m.ev_discharge[b,ev]/m.n\n",
    "      else:\n",
    "        return m.ev_soc[b,ev] == m.ev_soc[b-1,ev] + m.ev_charge[b,ev]*m.n - m.ev_discharge[b,ev]/m.n\n",
    "    model.soc_ev = pyo.Constraint(model.b, model.ev, rule = _soc_ev)\n",
    "\n",
    "\n",
    "    # Charging considering the EVs availability\n",
    "    def _charge_available(m,b,ev):\n",
    "      return m.ev_charge[b,ev] <= m.p_charger * m.availability[b,ev]\n",
    "    model.ch_available = pyo.Constraint(model.b, model.ev, rule = _charge_available)\n",
    "\n",
    "\n",
    "    # Discharging considering the EVs availability\n",
    "    def _discharge_available(m,b,ev):\n",
    "      return m.ev_discharge[b,ev] <= m.p_charger * m.availability[b,ev]\n",
    "    model.dch_available = pyo.Constraint(model.b, model.ev, rule = _discharge_available)\n",
    "\n",
    "\n",
    "    # Limit the power imported from the grid\n",
    "    def _limit_pImp(m,b):\n",
    "      #return m.pImp[b] <= min(0, sum(m.weights[t,i] * m.x[b, t, i] for t in m.t for i in m.i if i <= m.tim_lens[t]) - m.bin_capacities[b])\n",
    "      return m.pImp[b] <= m.M*m.is_importing[b];\n",
    "    model.limit_pImp = pyo.Constraint(model.b, rule = _limit_pImp)\n",
    "\n",
    "\n",
    "    # Limit for the power exported to the grid\n",
    "    def _limit_pExp(m,b):\n",
    "      return m.pExp[b] <= m.p_charger*(1-m.is_importing[b]);\n",
    "    model.limit_pExp = pyo.Constraint(model.b, rule = _limit_pExp)\n",
    "\n",
    "\n",
    "    # SOC minimum\n",
    "    def _soc_min(m,b,ev):\n",
    "      return m.ev_soc[b,ev] >= m.ev_soc_min[ev]\n",
    "    model.soc_min = pyo.Constraint(model.b, model.ev, rule = _soc_min)\n",
    "\n",
    "\n",
    "    # SOC maximum\n",
    "    def _soc_max(m,b,ev):\n",
    "      return m.ev_soc[b,ev] <= m.ev_soc_max[ev]\n",
    "    model.soc_max = pyo.Constraint(model.b, model.ev, rule = _soc_max)\n",
    "\n",
    "\n",
    "\n",
    "  def create_objective_function(self, model):\n",
    "\n",
    "    def _FOag(m):\n",
    "      #return sum(m.pImp[j]/1000*m.import_prices[j] - m.pExp[j]/1000*m.export_prices[j] for j in m.b)\n",
    "      return sum(m.pImp[j] for j in m.b)\n",
    "\n",
    "    model.FOag = pyo.Objective(rule = _FOag, sense = pyo.minimize)\n",
    "\n",
    "\n",
    "  def get_dataframes(self, model):\n",
    "\n",
    "    dataframes = {}\n",
    "\n",
    "    dataframes['mDf'] = ext_pyomo_vals(model.x).transpose()\n",
    "    dataframes['weight_df'] = ext_pyomo_vals(model.weights)\n",
    "    dataframes['timLens_df'] = ext_pyomo_vals(model.tim_lens)[0]\n",
    "    dataframes['production_df'] = ext_pyomo_vals(model.bin_capacities)[0]\n",
    "    dataframes['pImp_df'] = ext_pyomo_vals(model.pImp)[0]\n",
    "    dataframes['pExp_df'] = ext_pyomo_vals(model.pExp)[0]\n",
    "    dataframes['evCharge_df'] = ext_pyomo_vals(model.ev_charge).transpose()\n",
    "    dataframes['evDischarge_df'] = ext_pyomo_vals(model.ev_discharge).transpose()\n",
    "    dataframes['isImporting_df'] = ext_pyomo_vals(model.is_importing)[0]\n",
    "    dataframes['evSoc_df'] = ext_pyomo_vals(model.ev_soc).transpose()\n",
    "    dataframes['importPrices_df'] = ext_pyomo_vals(model.import_prices)[0]\n",
    "    dataframes['exportPrices_df'] = ext_pyomo_vals(model.export_prices)[0]\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "  def get_results(self, model, data):\n",
    "    print(\"Results\")\n",
    "    #print(ext_pyomo_vals(model.x))\n",
    "\n",
    "    self.dataframes = self.get_dataframes(model)\n",
    "\n",
    "    # Create dataframes\n",
    "    mDf = self.dataframes['mDf']\n",
    "    weight_df = self.dataframes['weight_df']\n",
    "    timLens_df = self.dataframes['timLens_df']\n",
    "    production_df = self.dataframes['production_df']\n",
    "    pImp_df = self.dataframes['pImp_df']\n",
    "    pExp_df = self.dataframes['pExp_df']\n",
    "    evCharge_df = self.dataframes['evCharge_df']\n",
    "    evDischarge_df = self.dataframes['evDischarge_df']\n",
    "    isImporting_df = self.dataframes['isImporting_df']\n",
    "    evSoc_df = self.dataframes['evSoc_df']\n",
    "    importPrices_df = self.dataframes['importPrices_df']\n",
    "    exportPrices_df = self.dataframes['exportPrices_df']\n",
    "\n",
    "    placed_timeslots = []\n",
    "\n",
    "\n",
    "    for b in np.arange(1, data['num_bins']+1):\n",
    "\n",
    "      print(\"------------------------------------------------------------\")\n",
    "      print(\"Bin {}\".format(b))\n",
    "      print(\"------------------------------------------------------------\")\n",
    "\n",
    "      for t in np.arange(1, data['num_items']+1):\n",
    "        for i in np.arange(1, data['max_len']+1):\n",
    "          if mDf[b].loc[(t, i)] == 1:\n",
    "            #print(\"Timeslot \", t, \"Item \", i, \" - weight: \", data['weights'][t-1][i-1])\n",
    "            print(\"Timeslot \", t, \"Item \", i)\n",
    "\n",
    "            firstItemDate = b - (i-1)\n",
    "\n",
    "            placed_timeslots.append(str(self.numbers[t-1][i-1]) + \"-\" + str(i-1) + \"-\" + str(self.items[t-1][i-1]) + \"-\" + str(b) + \"-\" + str(len(self.items[t-1])) + \"-\" + str(firstItemDate) + \"-\" + str(self.items_maximum[t-1][i-1]) + \"-\" + str(self.dates[t-1][i-1]) + \"-\" + str(self.flexibilities[t-1][i-1]))\n",
    "\n",
    "      demand_df = sum(weight_df.loc[(t,i)] * mDf[b].loc[(t, i)] for t in np.arange(1, data['num_items']+1) for i in np.arange(1, data['max_len']+1) if i <= timLens_df[t])\n",
    "\n",
    "\n",
    "      print(\"Production: \", production_df[b])\n",
    "      print(\"Demand: \", demand_df)\n",
    "      print(\"Excess of Production: \", (production_df[b]-demand_df))\n",
    "\n",
    "      print(\"Is Importing: \" + isImporting_df[b])\n",
    "      print(\"pImp: \", pImp_df[b])\n",
    "      print(\"pExp: \", pExp_df[b])\n",
    "\n",
    "      print(\"ev_charge: \")\n",
    "      print(evCharge_df[b])\n",
    "      print(\"ev_discharge: \")\n",
    "      print(evDischarge_df[b])\n",
    "\n",
    "      print(\"ev_soc: \")\n",
    "      print(evSoc_df[b])\n",
    "\n",
    "      print(\"import prices: \", importPrices_df[b])\n",
    "      print(\"export prices: \", exportPrices_df[b])\n",
    "\n",
    "      print('cost (+): ', exportPrices_df[b] * pExp_df[b]/1000)\n",
    "      print('cost (-):', importPrices_df[b] * pImp_df[b]/1000)\n",
    "\n",
    "    return placed_timeslots\n",
    "\n",
    "\n",
    "  def execute_knapsack(self):\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    start_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Start Time =\", start_time)\n",
    "\n",
    "    data = self.create_data_model()\n",
    "    model = pyo.ConcreteModel()\n",
    "\n",
    "    self.create_sets(model, data)\n",
    "    self.create_parameters(model, data)\n",
    "    self.create_variables(model)\n",
    "\n",
    "    self.create_constraints(model, data)\n",
    "    self.create_objective_function(model)\n",
    "\n",
    "\n",
    "    model.write('res_V4_EC.lp',  io_options={'symbolic_solver_labels': True})\n",
    "\n",
    "    opt = pyo.SolverFactory('cplex', executable='C:/Program Files/IBM/ILOG/CPLEX_Studio221/cplex/bin/x64_win64/cplex.exe')\n",
    "    opt.options['LogFile'] = 'res_V4_EC.log'\n",
    "\n",
    "    results = opt.solve(model)#, tee=True)\n",
    "    results.write()\n",
    "\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    end_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"End Time =\", end_time)\n",
    "    print(\"Dif: {}\".format(datetime.datetime.strptime(end_time, \"%H:%M:%S\") - datetime.datetime.strptime(start_time, \"%H:%M:%S\")))\n",
    "\n",
    "    placed_timeslots = self.get_results(model, data)\n",
    "    all_timeslots = []\n",
    "\n",
    "    for i in list(range(len(self.items))):\n",
    "      for p in range(len(self.items[i])):\n",
    "        w = self.items[i][p]\n",
    "        d = self.dates[i][p]\n",
    "        n = self.numbers[i][p]\n",
    "        flex = self.flexibilities[i][p]\n",
    "        max = self.items_maximum[i][p]\n",
    "        if (p == 0):  # First item of the timeslot\n",
    "          first_item_date = d\n",
    "        all_timeslots.append(str(n) + \"-\" + str(p) + \"-\" + str(w) + \"-\" + str(d) + \"-\" + str(len(self.items[i])) + \"-\" + str(first_item_date) + \"-\" + str(max) + \"-\" + str(d) + \"-\" + str(flex))\n",
    "\n",
    "\n",
    "    return [all_timeslots, placed_timeslots, [], []]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba475c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from CommunityManager import CommunityManager\n",
    "from ConsumptionGenerator import ConsumptionGenerator\n",
    "from Knapsack import Knapsack\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "import errno\n",
    "import datetime\n",
    "\n",
    "\n",
    "class CommunityManagerBalancingStrategy(CommunityManager):\n",
    "\n",
    "  def __init__(self, cg, path_steps_minutes, path_steps_after_first, path_steps_after_second):\n",
    "    \"\"\"\n",
    "    This class is a load balancing strategy implemented using Multiple Knapsack (which is a combinatorial optimization problem).\n",
    "    Taking in consideration the objective functions and constraints, it shifts the consumption of the activities.\n",
    "\n",
    "    Args:\n",
    "      cg: Consumption Generator instance (to allow to use its functions)\n",
    "      path_steps_minutes: path of the resampled consumption profiles (at 1/60Hz)\n",
    "      path_steps_after_first: path of the consumption profiles after the 1st step of the optimization\n",
    "      path_steps_after_second: path of the consumption profiles after the 2nd step of the optimization\n",
    "    \"\"\"\n",
    "    self.cg = cg\n",
    "    self.path_steps_minutes = path_steps_minutes\n",
    "    self.path_steps_after_first = path_steps_after_first\n",
    "    self.path_steps_after_second = path_steps_after_second\n",
    "    self.dataframes = {}\n",
    "\n",
    "\n",
    "  def calculate_bin_used_capacity(self, bins_capacities, placed_timeslots, production_baseload, n_bins_per_hour):\n",
    "    \"\"\"\n",
    "    Updates the bin capacity for the second part of the optimization (increases the production_baseload to the bin capacity of the first part, and subtracts the energy of the placed timeslots in the first step.\n",
    "\n",
    "    Args:\n",
    "      bins_capacities: bin capacities of the bins in the 1st step of the optimization\n",
    "      placed_timeslots: placed timeslots in the 1st step (in order to subtract the energy of them to the bin capacity) - if they are placed, the bin capacity decreases\n",
    "      production_baseload: value to increment in the bin capacities, which corresponds to the value of energy that can be acquired from the grid in the 2nd step\n",
    "      n_bins_per_hour: number of bins per hour (parameter of the strategy) to know the quantity of bins in a day (e.g. if bins of 30 minutes, n_bins_per_hour = 2)\n",
    "\n",
    "    Returns:\n",
    "      array with x positions in a day (where the number of positions is 24*n_bins_per_hour) with the bin capacity of each bin\n",
    "    \"\"\"\n",
    "\n",
    "    binUsedCapacity = [0] * 24 * n_bins_per_hour\n",
    "\n",
    "    for bin in range(len(bins_capacities)):\n",
    "      binUsedCapacity[bin] = bins_capacities[bin]\n",
    "      binUsedCapacity[bin] += production_baseload\n",
    "\n",
    "    for timeslot in placed_timeslots:\n",
    "      tm = timeslot.split(\"-\")\n",
    "      weight = float(tm[2])\n",
    "      bin = int(tm[3]) - 1  # bin 1 is 0 position (00:00-00:59)\n",
    "      binUsedCapacity[bin] -= weight\n",
    "\n",
    "    return binUsedCapacity\n",
    "\n",
    "\n",
    "  def get_production_max_after_first_optimization(self, netload_second_optim, fd, production_baseload, n_bins_per_hour, fact):\n",
    "    \"\"\"\n",
    "    Calculates the maximum production peak for each bin of the second step (calculates the maximum in the netload dataframe after updating the profiles of 1st step, and have to increase the production_baseload and decrease the energy of the placed timeslots of the 1st step)\n",
    "\n",
    "    Args:\n",
    "      netload_second_optim: dataframe which contains the netload after updating the profiles of the 1st step (to calculate the maximum peak in the 2nd step)\n",
    "      fd: consumption profile date (to\n",
    "      production_baseload: value to increment in the bin capacities, which corresponds to the value of energy that can be acquired from the grid in the 2nd step\n",
    "      n_bins_per_hour: number of bins per hour (parameter of the strategy) to know the quantity of bins in a day (e.g. if bins of 30 minutes, n_bins_per_hour = 2)\n",
    "      fact: minutes of each bin (e.g. if bins of 30 minutes, fact = 30)\n",
    "\n",
    "    Returns:\n",
    "      array with x positions in a day (where the number of positions is 24*n_bins_per_hour) with the bin maximum production peak of each bin\n",
    "    \"\"\"\n",
    "\n",
    "    bins_maximum_second_optimization = []\n",
    "    for z in range(0, 24):\n",
    "\n",
    "      startMin = 0\n",
    "      endMin = fact - 1\n",
    "      for w in range(0, n_bins_per_hour):\n",
    "        max = netload_second_optim[\n",
    "          (netload_second_optim['Date'] >= str(fd) + ' ' + str(z).zfill(2) + ':' + str(startMin).zfill(2) + ':00') & (\n",
    "              netload_second_optim['Date'] <= str(fd) + ' ' + str(z).zfill(2) + ':' + str(endMin).zfill(2) + ':00')][\n",
    "          'Production'].max()\n",
    "        # demand when the production is max\n",
    "        binUsage = netload_second_optim.loc[netload_second_optim[\n",
    "          (netload_second_optim['Date'] >= str(fd) + ' ' + str(z).zfill(2) + ':' + str(startMin).zfill(2) + ':00') & (\n",
    "              netload_second_optim['Date'] <= str(fd) + ' ' + str(z).zfill(2) + ':' + str(endMin).zfill(2) + ':00')][\n",
    "          'Production'].idxmax()][\"Demand\"]\n",
    "        bins_maximum_second_optimization.append(max + production_baseload - binUsage)\n",
    "\n",
    "        startMin = startMin + fact\n",
    "        endMin = endMin + fact\n",
    "\n",
    "    return bins_maximum_second_optimization\n",
    "\n",
    "\n",
    "  def remove_flexible_consumption(self):\n",
    "    \"\"\"\n",
    "    Removes the flexible consumption of the consumption profile, in order to have the baseload consumption (that consumption that can not be shifted.\n",
    "    In order to do this, the consumption of the flexible appliances are subtracted from the netload and community dataframes (notice that each flexible has it own consumption profile for each house)\n",
    "\n",
    "    Returns:\n",
    "      netload dataframe with the non-flexible consumption\n",
    "    \"\"\"\n",
    "\n",
    "    flexible_timeslots = self.cg.get_timeslots(self.cg.get_community(), True)\n",
    "\n",
    "    df_community = pd.read_csv(self.path_steps_after_first + '/community.csv', sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "    df_community.columns = ['Date', 'Power']\n",
    "\n",
    "    df_netload = pd.read_csv(self.path_steps_after_first + '/netload.csv', sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "    df_netload.columns = ['Date', 'Demand', 'PV_Production', 'Wind_Production', 'Production', 'Netload']\n",
    "\n",
    "\n",
    "    for timeslot in flexible_timeslots:\n",
    "\n",
    "      df_appliance = pd.read_csv(self.path_steps_after_first + '/house' + str(timeslot[\"House\"]) + '/' + timeslot[\"Appliance\"] + \".csv\", sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "      df_appliance.columns = ['Date', 'Power']\n",
    "\n",
    "      df_total = pd.read_csv(self.path_steps_after_first + '/house' + str(timeslot[\"House\"]) + '/total.csv', sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "      df_total.columns = ['Date', 'Power']\n",
    "\n",
    "      start_obj = datetime.datetime.strptime(timeslot[\"Start\"], '%Y-%m-%d %H:%M:%S')  # Convert string to datetime object\n",
    "      end_obj = datetime.datetime.strptime(timeslot[\"End\"], '%Y-%m-%d %H:%M:%S')  # Convert string to datetime object\n",
    "      obj = start_obj\n",
    "\n",
    "      while (obj != end_obj + datetime.timedelta(minutes=1)):\n",
    "\n",
    "        # Update house total consumption\n",
    "        indexTotal = df_total[df_total.Date == str(obj)].index  # Get index of the row\n",
    "\n",
    "        df_total.loc[indexTotal, 'Power'] = float(df_total[df_total.Date == str(obj)][\"Power\"]) - float(df_appliance[df_appliance.Date == str(obj)][\"Power\"])\n",
    "\n",
    "        # Update community consumption\n",
    "        indexCommunity = df_community[df_community.Date == str(obj)].index  # Get index of the row\n",
    "        df_community.loc[indexCommunity, 'Power'] = float(df_community[df_community.Date == str(obj)][\"Power\"]) - float(df_appliance[df_appliance.Date == str(obj)][\"Power\"])\n",
    "\n",
    "\n",
    "        # Update community netload\n",
    "        indexNetload = df_netload[df_netload.Date == str(obj)].index  # Get index of the row\n",
    "        df_netload.loc[indexNetload, 'Demand'] = float(df_netload[df_netload.Date == str(obj)][\"Demand\"]) - float(df_appliance[df_appliance.Date == str(obj)][\"Power\"])\n",
    "\n",
    "        # Update appliance consumption - has to be the last update since the others dataframes use this dataframe\n",
    "        indexAppliance = df_appliance[df_appliance.Date == str(obj)].index  # Get index of the row\n",
    "        df_appliance.loc[indexAppliance, 'Power'] = 0\n",
    "\n",
    "        obj = obj + datetime.timedelta(minutes=1)  # Next minute\n",
    "\n",
    "\n",
    "      # After all minutes of the appliance updated\n",
    "      output_directory = os.path.join('', self.path_steps_after_first + '/house' + str(timeslot[\"House\"]))\n",
    "\n",
    "      outname = os.path.join(output_directory, str(timeslot[\"Appliance\"]) + '.csv')\n",
    "      df_appliance.to_csv(outname, columns=['Date', 'Power'], sep=\";\", index=False)\n",
    "\n",
    "      outname = os.path.join(output_directory, 'total.csv')\n",
    "      df_total.to_csv(outname, columns=['Date', 'Power'], sep=\";\", index=False)\n",
    "\n",
    "    output_directory = os.path.join('', self.path_steps_after_first)\n",
    "    outname = os.path.join(output_directory, 'community.csv')\n",
    "    df_community.to_csv(outname, columns=['Date', 'Power'], sep=\";\", index=False)\n",
    "\n",
    "    outname = os.path.join(output_directory, 'netload.csv')\n",
    "    df_netload.to_csv(outname, columns=['Date', 'Demand', 'PV_Production', 'Wind_Production', 'Production', 'Netload'], sep=\";\", index=False)\n",
    "\n",
    "    return df_netload\n",
    "\n",
    "\n",
    "\n",
    "  def create_profiles_after_strategy(self, placed_timeslots, all_timeslots_objects, initial_path, final_path, short_initial_path, short_final_path, remove_flex_cons, n_bins_per_hour, fact):\n",
    "    \"\"\"\n",
    "    Implementing the abstract function (from the parent) which updates the profiles after applying the strategy.\n",
    "\n",
    "    Args:\n",
    "      placed_timeslots: array of the placed timeslots\n",
    "      all_timeslots_objects: array of all timeslots with all the information (Start, End, Appliance, Power, House, etc)\n",
    "      initial_path: path of the minutes (1/60Hz) dataframe (e.g. \"(...)/output/minute\")\n",
    "      final_path: path of the dataframe after the strategy (e.g. \"(...)/output/afteroptimization\")\n",
    "      short_initial_path: folder of the minutes (1/60Hz) dataframe (e.g. \"minutes\")\n",
    "      short_final_path: folder of the dataframe after the strategy e.g. \"afteroptimization\")\n",
    "      remove_flex_cons: if True, the flexible consumption will be removed, otherwise the flexible consumption will not be removed (in 1st step, it was True to remove the flexible consumption and in the 2nd step it was False because the flexible consumption has already been removed)\n",
    "      n_bins_per_hour: number of bins per hour (parameter of the strategy) to know the quantity of bins in a day (e.g. if bins of 30 minutes, n_bins_per_hour = 2)\n",
    "      fact: minutes of each bin (e.g. if bins of 30 minutes, fact = 30)\n",
    "\n",
    "    Returns:\n",
    "      output of update_consumption_profiles_based_on_optimization function\n",
    "    \"\"\"\n",
    "    return self.update_consumption_profiles_based_on_optimization(placed_timeslots, all_timeslots_objects, initial_path, final_path, short_initial_path, short_final_path, remove_flex_cons, n_bins_per_hour, fact)\n",
    "\n",
    "\n",
    "  def update_consumption_profiles_based_on_optimization(self, placed_timeslots, all_timeslots_objects, initial_path, final_path, short_initial_path, short_final_path, remove_flex_cons, n_bins_per_hour, fact):\n",
    "    \"\"\"\n",
    "    Implementing the function which updates the profiles after applying the strategy.\n",
    "\n",
    "    Args:\n",
    "      placed_timeslots: array of the placed timeslots\n",
    "      all_timeslots_objects: array of all timeslots with all the information (Start, End, Appliance, Power, House, etc)\n",
    "      initial_path: path of the minutes (1/60Hz) dataframe (e.g. \"(...)/output/minute\")\n",
    "      final_path: path of the dataframe after the strategy (e.g. \"(...)/output/afteroptimization\")\n",
    "      short_initial_path: folder of the minutes (1/60Hz) dataframe (e.g. \"minutes\")\n",
    "      short_final_path: folder of the dataframe after the strategy e.g. \"afteroptimization\")\n",
    "      remove_flex_cons: if True, the flexible consumption will be removed, otherwise the flexible consumption will not be removed (in 1st step, it was True to remove the flexible consumption and in the 2nd step it was False because the flexible consumption has already been removed)\n",
    "      n_bins_per_hour: number of bins per hour (parameter of the strategy) to know the quantity of bins in a day (e.g. if bins of 30 minutes, n_bins_per_hour = 2)\n",
    "      fact: minutes of each bin (e.g. if bins of 30 minutes, fact = 30)\n",
    "\n",
    "    Returns:\n",
    "      array with 2 positions: array of the placed timeslots [0] and flexible dataframe [1]\n",
    "    \"\"\"\n",
    "    # Remove all files of the folder and the folder (before copying the consumption profiles)\n",
    "    if os.path.exists(final_path):\n",
    "      shutil.rmtree(final_path)\n",
    "\n",
    "    # Create the folder\n",
    "    if not os.path.exists(final_path):\n",
    "      os.mkdir(final_path)\n",
    "\n",
    "\n",
    "    # Copy the consumption profiles to after optimization folder in order to change it consumption after the optimization of the timeslots\n",
    "    try:\n",
    "      src_files = os.listdir(initial_path)\n",
    "      for file_name in src_files:\n",
    "        full_file_name = os.path.join(initial_path, file_name)\n",
    "        if os.path.isfile(full_file_name):\n",
    "          shutil.copy(full_file_name, final_path)\n",
    "        elif os.path.isdir(full_file_name):\n",
    "          shutil.copytree(full_file_name, full_file_name.replace(short_initial_path, short_final_path))\n",
    "    except OSError as e:\n",
    "      if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "\n",
    "    # community profile\n",
    "    # communityBefore = pd.read_csv('output/minute/community.csv', sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "    # communityBefore.columns = ['Date', 'Power']\n",
    "\n",
    "\n",
    "    df_flexible = \"\"\n",
    "    if (remove_flex_cons):\n",
    "      df_flexible = self.remove_flexible_consumption()\n",
    "      #showNetloadGraph(finalPath + '/netload.csv')\n",
    "\n",
    "\n",
    "    community_after = pd.read_csv(final_path + '/community.csv', sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "    community_after.columns = ['Date', 'Power']\n",
    "\n",
    "    netload_after = pd.read_csv(final_path + '/netload.csv', sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "    netload_after.columns = ['Date', 'Demand', 'PV_Production', 'Wind_Production', 'Production', 'Netload']\n",
    "\n",
    "\n",
    "    # Reset community consumption\n",
    "    #community_after['Power'] = 0\n",
    "    #netload_after['Demand'] = 0\n",
    "\n",
    "\n",
    "    placed_appliances = []\n",
    "    placed_houses = []\n",
    "    placed_timeslots_array = []\n",
    "\n",
    "\n",
    "    for timeslot in placed_timeslots:\n",
    "\n",
    "      timeslot = timeslot.split(\"-\")\n",
    "      first_item_date = str(int(timeslot[5])-1)\n",
    "      timeslot_number = int(timeslot[0])\n",
    "      timeslot_sub_item_number = int(timeslot[1])\n",
    "      timeslot_power = float(timeslot[2])\n",
    "      timeslot_first_bin = str(int(timeslot[3]) - 1) # bin 1 corresponds to midnight, bin 2 corresponds to 1 am, etc\n",
    "      timeslot_number_of_bins = timeslot[4]\n",
    "      timeslot_last_bin = str(int(first_item_date) + (int(timeslot_number_of_bins) - 1))\n",
    "      timeslot_bin_before_opt = str(int(timeslot[7]) - 1)\n",
    "\n",
    "\n",
    "      # Gets all the fields of the timeslot (Start, End, Appliance, House, etc)\n",
    "      timeslot_obj = all_timeslots_objects[timeslot_number]  # If a timeslot is placed, all the subitemms are placed\n",
    "\n",
    "      # each house consumption profile\n",
    "      # total_before = pd.read_csv('output/minute/house' + str(timeslotObj[\"House\"]) + '/total.csv', sep=';')\n",
    "      # total_before.columns = ['Date', 'Power']\n",
    "\n",
    "      total_after = pd.read_csv(final_path + '/house' + str(timeslot_obj[\"House\"]) + '/total.csv', sep=';')\n",
    "      total_after.columns = ['Date', 'Power']\n",
    "\n",
    "      # Reset all houses consumption\n",
    "      #if (str(timeslot_obj[\"House\"]) not in placed_houses):\n",
    "        #total_after['Power'] = 0\n",
    "        #placed_houses.append(str(timeslot_obj[\"House\"]))\n",
    "\n",
    "      # each appliance consumption profile (of a specific house)\n",
    "      df_before = pd.read_csv(self.path_steps_minutes + '/house' + str(timeslot_obj[\"House\"]) + '/' + timeslot_obj[\"Appliance\"] + \".csv\", sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "      df_before.columns = ['Date', 'Power']\n",
    "\n",
    "      df_after = pd.read_csv(final_path + '/house' + str(timeslot_obj[\"House\"]) + '/' + timeslot_obj[\"Appliance\"] + \".csv\", sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "      df_after.columns = ['Date', 'Power']\n",
    "\n",
    "      # Reset all appliance consumption\n",
    "      #if ((str(timeslot_obj[\"House\"]) + \"-\" + str(timeslot_obj[\"Appliance\"])) not in placed_appliances):\n",
    "        #dfAfter['Power'] = 0\n",
    "        #placed_appliances.append(str(timeslot_obj[\"House\"]) + \"-\" + str(timeslot_obj[\"Appliance\"]))\n",
    "\n",
    "      # when there's more than one item of a timeslot:\n",
    "      # 1) if its the first hour - starts at the first minutes of the timeslot and ends at 59 miutes\n",
    "      # 2) if its a middle hour (not the first and not the last) - starts at 00 minutes and ends at 59 minutes\n",
    "      # 3) if its the last hour - starts at 00 and ends at the last minutes of the timeslot\n",
    "      # e.g. timeslot from 8.53 to 10.15:\n",
    "      # hour 8 (bin 9) -> 08:53 (original) - 08:59 (first)\n",
    "      # hour 9 (bin 10) -> 09:00 - 09:59 (middle)\n",
    "      # hour 10 (bin 11) -> 10:00 - 10:15 (original) (last)\n",
    "\n",
    "      tim_new_hour = int(math.floor(int(timeslot_first_bin)/n_bins_per_hour))\n",
    "      tim_new_min = int((int(timeslot_first_bin)%n_bins_per_hour)*fact)\n",
    "      tim_old_hour = int(math.floor(int(timeslot_bin_before_opt)/n_bins_per_hour))\n",
    "      tim_old_min = int((int(timeslot_bin_before_opt) % n_bins_per_hour) * fact)\n",
    "\n",
    "\n",
    "      if (int(timeslot_number_of_bins) > 1):\n",
    "        if (int(first_item_date) == int(timeslot_first_bin)):\n",
    "\n",
    "          timeslot_start_date = str(timeslot_obj[\"Start\"])\n",
    "          timeslot_end_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_old_hour).zfill(2) + \":\" + str(tim_old_min + (fact - 1)).zfill(2) + \":00\"\n",
    "          new_optimization_start_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_new_hour).zfill(2) + \":\" + str(int(tim_new_min+(fact-1)) - (int(tim_old_min+(fact-1))-int(timeslot_obj[\"Start\"][14:16]))).zfill(2) + \":00\"\n",
    "          new_optimization_end_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_new_hour).zfill(2) + \":\" + str(tim_new_min + (fact - 1)).zfill(2) + \":00\"\n",
    "\n",
    "        elif (int(timeslot_first_bin) == int(timeslot_last_bin)):\n",
    "\n",
    "          timeslot_start_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_old_hour).zfill(2) + \":\" + str(tim_old_min).zfill(2) + \":00\"\n",
    "          timeslot_end_date = str(timeslot_obj[\"End\"])\n",
    "          new_optimization_start_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_new_hour).zfill(2) + \":\" + str(tim_new_min).zfill(2) + \":00\"\n",
    "          new_optimization_end_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_new_hour).zfill(2) + \":\" + str(int(tim_new_min) + (int(timeslot_obj[\"End\"][14:16])-int(tim_old_min))).zfill(2) + \":00\"\n",
    "\n",
    "        else:\n",
    "\n",
    "          timeslot_start_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_old_hour).zfill(2) + \":\" + str(tim_old_min).zfill(2) + \":00\"\n",
    "          timeslot_end_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_old_hour).zfill(2) + \":\" + str(tim_old_min + (fact - 1)).zfill(2) + \":00\"\n",
    "          new_optimization_start_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_new_hour).zfill(2) + \":\" + str(tim_new_min).zfill(2) + \":00\"\n",
    "          new_optimization_end_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_new_hour).zfill(2) + \":\" + str(tim_new_min + (fact - 1)).zfill(2) + \":00\"\n",
    "\n",
    "      else:\n",
    "\n",
    "        timeslot_start_date = str(timeslot_obj[\"Start\"])\n",
    "        timeslot_end_date = str(timeslot_obj[\"End\"])\n",
    "        new_optimization_start_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_new_hour).zfill(2) + \":\" + str(int(tim_new_min + (fact - 1)) - (int(tim_old_min + (fact - 1)) - int(timeslot_obj[\"Start\"][14:16]))).zfill(2) + \":00\"\n",
    "        new_optimization_end_date = str(timeslot_obj[\"Start\"])[0:11] + str(tim_new_hour).zfill(2) + \":\" + str(int(tim_new_min) + (int(timeslot_obj[\"End\"][14:16]) - int(tim_old_min))).zfill(2) + \":00\"\n",
    "\n",
    "\n",
    "      # list of placed timeslots\n",
    "      placed_timeslots_array.append(str(timeslot_obj[\"House\"]) + \"*\" + str(timeslot_obj[\"Appliance\"]) + \"*\" + str(timeslot_number) + \"*\" + str(new_optimization_start_date) + \"*\" + str(new_optimization_end_date))\n",
    "\n",
    "\n",
    "      # before optimization (original)\n",
    "      start_obj_before = datetime.datetime.strptime(timeslot_start_date, '%Y-%m-%d %H:%M:%S')  # Convert string to datetime object\n",
    "      end_obj_before = datetime.datetime.strptime(timeslot_end_date, '%Y-%m-%d %H:%M:%S')  # Convert string to datetime object\n",
    "      obj_before = start_obj_before\n",
    "\n",
    "      # after optimization\n",
    "      start_obj_after = datetime.datetime.strptime(new_optimization_start_date, '%Y-%m-%d %H:%M:%S')  # Convert string to datetime object\n",
    "      end_obj_after = datetime.datetime.strptime(new_optimization_end_date, '%Y-%m-%d %H:%M:%S')  # Convert string to datetime object\n",
    "      obj_after = start_obj_after\n",
    "\n",
    "\n",
    "      while (obj_after != end_obj_after + datetime.timedelta(minutes=1)):\n",
    "\n",
    "\n",
    "        index_netload_after = netload_after[netload_after.Date == str(obj_after)].index  # Get index of the row\n",
    "        index_after = community_after[community_after.Date == str(obj_after)].index  # Get index of the row\n",
    "        index_total_after = total_after[total_after.Date == str(obj_after)].index  # sGet index of the row\n",
    "        index_app_after = df_after[df_after.Date == str(obj_after)].index  # Get index of the row\n",
    "\n",
    "        netload_after.loc[index_netload_after, 'Demand'] = float(netload_after[netload_after.Date == str(obj_after)][\"Demand\"]) + float(df_before[df_before.Date == str(obj_before)][\"Power\"])  # Subtract the energy of that timeslot from the community energy\n",
    "        netload_after.loc[netload_after['Production'] < 0, 'Production'] = 0\n",
    "\n",
    "\n",
    "        community_after.loc[index_after, 'Power'] = float(community_after[community_after.Date == str(obj_after)][\"Power\"]) + float(df_before[df_before.Date == str(obj_before)][\"Power\"])  # Subtract the energy of that timeslot from the community energy\n",
    "\n",
    "        total_after.loc[index_total_after, 'Power'] = float(total_after[total_after.Date == str(obj_after)][\"Power\"]) + float(df_before[df_before.Date == str(obj_before)][\"Power\"])  # Subtract the energy of that timeslot from the total energy of that house (the house which corresponds the timeslot)\n",
    "        df_after.loc[index_app_after, 'Power'] = float(df_after[df_after.Date == str(obj_after)][\"Power\"]) + float(df_before[df_before.Date == str(obj_before)][\"Power\"])  # Subtract the energy of that timeslot from the total energy of that house (the house which corresponds the timeslot)\n",
    "\n",
    "        obj_before = obj_before + datetime.timedelta(minutes=1)  # Next minute\n",
    "        obj_after = obj_after + datetime.timedelta(minutes=1)  # Next minute\n",
    "\n",
    "\n",
    "      # After while - when the consumption profile is updated for each minute of the timeslot\n",
    "      output_directory = os.path.join('', final_path + '/house' + str(timeslot_obj[\"House\"]))\n",
    "      outname = os.path.join(output_directory, str(timeslot_obj[\"Appliance\"]) + '.csv')\n",
    "      df_after.to_csv(outname, columns=['Date', 'Power'], sep=\";\", index=False)\n",
    "\n",
    "      # After all timeslots updated - update the total of each house\n",
    "      output_directory = os.path.join('', final_path + '/house' + str(timeslot_obj[\"House\"]))\n",
    "      outname = os.path.join(output_directory, 'total.csv')\n",
    "      df_after.to_csv(outname, columns=['Date', 'Power'], sep=\";\", index=False)\n",
    "\n",
    "    netload_after[\"Netload\"] = netload_after[\"Demand\"] - netload_after[\"Production\"]\n",
    "\n",
    "    # After all timeslots updated - update the community profile\n",
    "    output_directory = os.path.join('', final_path)\n",
    "    outname = os.path.join(output_directory, 'community.csv')\n",
    "    community_after.to_csv(outname, columns=['Date', 'Power'], sep=\";\", index=False)\n",
    "\n",
    "    # After all timeslots updated - update the community profile\n",
    "    outname = os.path.join(output_directory, 'netload.csv')\n",
    "    netload_after.to_csv(outname, columns=['Date', 'Demand', 'PV_Production', 'Wind_Production', 'Production', 'Netload'], sep=\";\", index=False)\n",
    "\n",
    "\n",
    "    return [placed_timeslots_array, df_flexible]\n",
    "\n",
    "\n",
    "  def execute(self, export_prices_hour = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], import_prices_hour = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]):\n",
    "    \"\"\"\n",
    "    Executes the optimization process (implemented strategy using Multiple Knapsack):\n",
    "    1) First step\n",
    "    - Prepares the input (arrays) for the process (bin_capacities, bin_maximums, timeslots_number, flexibitilies, items_max, etc)\n",
    "    - Calls the Knapsack class with the input processed (execute_knapsack function)\n",
    "    - Updates the consumption profiles based on the output of the knapsack\n",
    "    2) Second Step\n",
    "    - Prepares the input (arrays) for the process (bin_capacities, bin_maximums, timeslots_number, flexibitilies, items_max, etc)\n",
    "    - Calls the Knapsack class with the input processed (execute_knapsack function)\n",
    "    - Updates the consumption profiles based on the output of the knapsack\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Optimization the community using the implemented strategy\")\n",
    "\n",
    "    netload = pd.read_csv(self.path_steps_minutes + '/netload.csv',\n",
    "                          sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "    netload.columns = ['Date', 'Demand', 'PV_Production', 'Wind_Production', 'Production', 'Netload']\n",
    "\n",
    "    # Plotd\n",
    "    # netload.plot(x=\"Date\", y=[\"Demand\", \"Production\", \"Netload\"], kind=\"line\", figsize=(10, 10))\n",
    "    # plt.show()\n",
    "\n",
    "    fd = str(netload.iloc[0][\"Date\"])[0:10]\n",
    "    bins_capacities = []\n",
    "    bins_maximum = []\n",
    "    bins_export_prices = []\n",
    "    bins_import_prices = []\n",
    "    fact = 60\n",
    "    n_bins_per_hour = int(60 / fact)\n",
    "\n",
    "    for z in range(0, 24):\n",
    "      startMin = 0\n",
    "      endMin = fact - 1\n",
    "      for w in range(0, n_bins_per_hour):\n",
    "        avg = netload[\n",
    "          (netload['Date'] >= str(fd) + ' ' + str(z).zfill(2) + ':' + str(startMin).zfill(2) + ':00') & (\n",
    "                  netload['Date'] <= str(fd) + ' ' + str(z).zfill(2) + ':' + str(endMin).zfill(2) + ':00')][\n",
    "          'Production'].mean()\n",
    "        max = netload[\n",
    "          (netload['Date'] >= str(fd) + ' ' + str(z).zfill(2) + ':' + str(startMin).zfill(2) + ':00') & (\n",
    "                  netload['Date'] <= str(fd) + ' ' + str(z).zfill(2) + ':' + str(endMin).zfill(2) + ':00')][\n",
    "          'Production'].max()\n",
    "        #bins_capacities.append(avg)\n",
    "        bins_capacities.append(avg+5000)\n",
    "        bins_maximum.append(max)\n",
    "        bins_export_prices.append(export_prices_hour[z])\n",
    "        bins_import_prices.append(import_prices_hour[z])\n",
    "\n",
    "        startMin = startMin + fact\n",
    "        endMin = endMin + fact\n",
    "\n",
    "    self.timeslots = self.cg.get_timeslots(self.cg.get_community(), True)\n",
    "\n",
    "    community = self.cg.get_community()\n",
    "    appliances_flexibility = {\"DISHWASHER\": 12, \"VACUUMCLEANER\": 8, \"WASHINGMACHINE\": 10, \"DRYER\": 5, \"IRON\": 5,\n",
    "                             \"COOKINGSTOVE\": 1}\n",
    "    # appliances_flexibility = {\"DISHWASHER\": 12, \"VACUUMCLEANER\": 12, \"WASHINGMACHINE\": 12, \"DRYER\": 12, \"IRON\": 12, \"COOKINGSTOVE\": 12}\n",
    "    flexibilities_array = self.cg.get_community_flexibility(community)\n",
    "    contracted_power = self.cg.calculate_contracted_power(community)\n",
    "\n",
    "    dates = []\n",
    "    items = []\n",
    "    items_max = []\n",
    "    timeslot_numbers = []\n",
    "    count = 0\n",
    "    flexibilities = []\n",
    "\n",
    "    print(\"Timeslots List\")\n",
    "    for timeslot in self.timeslots:\n",
    "\n",
    "      print(timeslot)\n",
    "\n",
    "      # Fill timeslots (with subitems) array\n",
    "      df = pd.read_csv(self.path_steps_minutes + '/house' + str(timeslot['House']) + '/' + timeslot['Appliance'] + \".csv\",\n",
    "                       sep=';')  # Header=None to indicate that the first row is data and not colummn names\n",
    "      df.columns = ['Date', 'Power']\n",
    "      df = df[:24 * 60 * 60]  # Only the first day is important (24 hours * 60 minutes * 60 seconds)\n",
    "      # df = df.fillna(0) # fills nan with 0\n",
    "\n",
    "      # Fill dates array\n",
    "      start_hour = int(str(timeslot['Start'])[11:13])\n",
    "      end_hour = int(str(timeslot['End'])[11:13])\n",
    "      start_date = str(timeslot['Start'])[0:10]\n",
    "      start_minute = int(str(timeslot['Start'])[14:16])\n",
    "      end_minute = int(str(timeslot['End'])[14:16])\n",
    "\n",
    "      hour = start_hour\n",
    "      temp_date = []\n",
    "      temp_tim = []\n",
    "      temp_num = []\n",
    "      temp_max = []\n",
    "      temp_flex = []\n",
    "\n",
    "      while (hour <= end_hour):\n",
    "\n",
    "        for w in range(0, n_bins_per_hour):\n",
    "\n",
    "          if (n_bins_per_hour > 1):\n",
    "            # for example, if we have bins of 30 minutes and the startMinute is 30 or higher, then we just have the second bin of that hour\n",
    "            if (w != n_bins_per_hour - 1 and hour == start_hour and start_minute >= fact * (w + 1)):\n",
    "              continue\n",
    "\n",
    "            if (hour == end_hour and end_minute < fact * w):\n",
    "              continue\n",
    "\n",
    "          if (hour == start_hour and start_minute < fact * (w + 1) and start_minute >= fact * w):\n",
    "            start = start_minute\n",
    "          else:\n",
    "            start = w * fact\n",
    "\n",
    "          if (hour == end_hour and fact * (w + 1) >= end_minute):\n",
    "            end = end_minute\n",
    "          elif (hour == start_hour and w == 0):\n",
    "            end = fact - 1\n",
    "          else:\n",
    "            end = (w + 1) * fact - 1\n",
    "\n",
    "          duration_in_minutes = end - start + 1\n",
    "          tim = (df[(df['Date'] >= str(start_date) + ' ' + str(hour).zfill(2) + ':' + str(start).zfill(2) + ':00') & (\n",
    "                  df['Date'] <= str(start_date) + ' ' + str(hour).zfill(2) + ':' + str(end).zfill(2) + ':00')][\n",
    "                   'Power'].mean()) * (duration_in_minutes / 60)\n",
    "          max = df[(df['Date'] >= str(start_date) + ' ' + str(hour).zfill(2) + ':' + str(start).zfill(2) + ':00') & (\n",
    "                  df['Date'] <= str(start_date) + ' ' + str(hour).zfill(2) + ':' + str(end).zfill(2) + ':00')][\n",
    "            'Power'].max()\n",
    "\n",
    "          temp_date.append((hour * n_bins_per_hour) + w + 1)  # 10 am corresponds to bin 11\n",
    "          temp_tim.append(tim)\n",
    "          temp_max.append(max)\n",
    "          temp_num.append(count)\n",
    "          temp_flex.append(flexibilities_array[int(timeslot['House'])] * appliances_flexibility[timeslot['Appliance']])\n",
    "\n",
    "        hour = hour + 1\n",
    "\n",
    "      dates.append(temp_date)\n",
    "      items.append(temp_tim)\n",
    "      items_max.append(temp_max)\n",
    "      timeslot_numbers.append(temp_num)\n",
    "      flexibilities.append(temp_flex)\n",
    "      count = count + 1\n",
    "\n",
    "\n",
    "    # EVs inputs from EVs simulator\n",
    "    evs_data = {}\n",
    "    evs_data['EVs_Inputs'] = pd.read_csv('../evs_inputs/EVs_Inputs.csv')\n",
    "    evs_data['availability'] = pd.read_csv('../evs_inputs/alpha.csv')\n",
    "\n",
    "    initial_soc = evs_data['EVs_Inputs'].to_numpy()[:,0] * 1000\n",
    "    evs_min = evs_data['EVs_Inputs'].to_numpy()[:,1] * 1000\n",
    "    evs_max = evs_data['EVs_Inputs'].to_numpy()[:,2] * 1000\n",
    "    evs_availability = evs_data['availability'].to_numpy()\n",
    "    efficiency = 0.9\n",
    "    p_charger = 7200\n",
    "\n",
    "\n",
    "    # print(dates)\n",
    "    print(\"Community Flexibilities:\")\n",
    "    print(flexibilities)\n",
    "    print(\"Bin Capacities:\")\n",
    "    print(bins_capacities)\n",
    "    print(\"Bin Maximum:\")\n",
    "    print(bins_maximum)\n",
    "    print(\"Dates:\")\n",
    "    print(dates)\n",
    "    print(\"Timeslots:\")\n",
    "    print(items)\n",
    "    print(\"Timeslots Maximum:\")\n",
    "    print(items_max)\n",
    "    print(\"Numbers:\")\n",
    "    print(timeslot_numbers)\n",
    "    print(\"Export Price:\")\n",
    "    print(bins_export_prices)\n",
    "    print(\"Import Price:\")\n",
    "    print(bins_import_prices)\n",
    "\n",
    "    self.production_baseload = 0.85 * float(contracted_power)\n",
    "\n",
    "    num_evs = 2\n",
    "\n",
    "    exec = KnapsackBalancing(dates, items, bins_capacities, timeslot_numbers, bins_maximum, items_max, self.production_baseload, fact, n_bins_per_hour, flexibilities, bins_export_prices, bins_import_prices, num_evs, evs_max, evs_min, initial_soc, evs_availability, efficiency, p_charger)\n",
    "    otimization = exec.execute_knapsack()\n",
    "    self.dataframes = exec.dataframes\n",
    "\n",
    "    # Remove all the consumption (all timeslots - placed and not placed ones)\n",
    "    # Add the consumption of the placed timeslots (just the ones that were placed by the optimization process)\n",
    "    self.placed_timeslots = otimization[1]\n",
    "    self.not_placed_timeslots = otimization[2]\n",
    "\n",
    "    # showNetloadGraph('output/minute/netload.csv')\n",
    "\n",
    "    updt = self.create_profiles_after_strategy(self.placed_timeslots, self.timeslots, self.path_steps_minutes, self.path_steps_after_first, self.path_steps_minutes.split(\"/\")[-1], self.path_steps_after_first.split(\"/\")[-1], True, n_bins_per_hour, fact)\n",
    "    placed_timeslots_array = updt[0]\n",
    "    df_flexible = updt[1]\n",
    "\n",
    "\n",
    "    # community = ConsumptionGenerator.get_community()\n",
    "    # ConsumptionGenerator.show_community_graph(community, 'output/minute/house')\n",
    "    # ConsumptionGenerator.show_community_graph(community, 'output/afterknapsack/house')\n",
    "    # ConsumptionGenerator.show_community_graph(community, 'output/afteroptimization/house')\n",
    "    # ConsumptionGenerator.show_community_graph(community, 'output/afterexchanges/house')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#prices from https://www.omie.es/pt/market-results/daily/daily-market/daily-hourly-price 12/12/2022 for Portugal\n",
    "buy_price_hour = [85.6,4.11,4.11,4.11,4.11,4.11,4.11,75.83,96.2,131.01,139.92,139.5,135.05,140,142,140.13,147,146.08,139.92,140.03,142,146.08,134.45,99]\n",
    "#buy_price_hour_kwh =[]\n",
    "#for i in buy_price_hour:\n",
    "#  buy_price_hour_kwh.append(i/1000)\n",
    "#hour = lambda hour:buy_price_hour_kwh[hour]\n",
    "\n",
    "buy_price_hour_kwh = [0.0918, 0.0918, 0.0918, 0.0918, 0.0918, 0.0918, 0.0918, 0.0918, 0.2417, 0.2417, 0.2417, 0.1484, 0.1484, 0.1484, 0.1484, 0.1484, 0.1484, 0.1484, 0.2417, 0.2417, 0.2417, 0.1484, 0.0918, 0.0918]\n",
    "\n",
    "sell_price_hour_kwh = [0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163,0.1163]\n",
    "\n",
    "\n",
    "\n",
    "#first_opt = pd.read_csv(path_steps_after_first + '/netload.csv', sep=';')\n",
    "#first_opt.columns = ['Date', 'Demand', 'PV_Production', 'Wind_Production', 'Production', 'Netload']\n",
    "#first_opt['Date'] = pd.to_datetime(first_opt['Date'])\n",
    "#first_opt.set_index('Date')\n",
    "\n",
    "\n",
    "cm = CommunityManagerBalancingStrategy(cg, path_steps_minutes, path_steps_after_first, path_steps_after_second)\n",
    "cm.execute(export_prices_hour = sell_price_hour_kwh, import_prices_hour=buy_price_hour_kwh)\n",
    "\n",
    "# Getting the consumption profiles after the 1st step of the optimization\n",
    "opt = pd.read_csv(path_steps_after_first + '/netload.csv', sep=';')\n",
    "opt.columns = ['Date', 'Demand', 'PV_Production', 'Wind_Production', 'Production', 'Netload']\n",
    "opt['Date'] = pd.to_datetime(opt['Date'])\n",
    "opt.set_index('Date')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "opt[:24*60*1][\"Demand\"].plot(legend=True, label='Demand')\n",
    "opt[:24*60*1][\"Production\"].plot(legend=True, label='Production')\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.xlabel(\"Time (Hours)\")\n",
    "plt.ylabel(\"Power (W)\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509a14a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "before = pd.read_csv(path_steps_minutes + '/netload.csv', sep=';')\n",
    "before.columns = ['Date', 'Demand', 'PV_Production', 'Wind_Production', 'Production', 'Netload']\n",
    "before['Date'] = pd.to_datetime(before['Date'])\n",
    "before.set_index('Date')\n",
    "\n",
    "before[:24*60*1][\"Demand\"].plot(legend=True, label='Demand')\n",
    "before[:24*60*1][\"Production\"].plot(legend=True, label='Production')\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.xlabel(\"Time (Hours)\")\n",
    "plt.ylabel(\"Power (W)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the difference between Demand and Production\n",
    "opt['Difference'] = opt['Demand'] - opt['Production']\n",
    "\n",
    "# Plot the difference\n",
    "opt[:24*60*1][\"Difference\"].plot(legend=True, label='Difference')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_energy_used_from_grid(df):\n",
    "  return df['pImp_df'].sum()/1000\n",
    "\n",
    "def get_energy_used_from_production(df):\n",
    "  return (df['production_df'].sum() - df['pExp_df'].sum())/1000\n",
    "\n",
    "def get_energy_not_used_from_production(df):\n",
    "  return df['pExp_df'].sum()/1000\n",
    "\n",
    "def get_self_sufficiency(df):\n",
    "  return get_energy_used_from_production(df) / (get_energy_used_from_grid(df) + get_energy_used_from_production(df))*100\n",
    "\n",
    "def get_self_consumption(df):\n",
    "  return get_energy_used_from_production(df) / (get_energy_used_from_production(df) + get_energy_not_used_from_production(df))*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = cm.dataframes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the metrics for the input\n",
    "evaluation_in = Evaluation(before.iloc[:24*60], 0)\n",
    "\n",
    "print(\"Energy Used from Grid: \" + \"{:.2f}\".format(evaluation_in.get_energy_used_from_grid()) + \" kWh\")\n",
    "print(\"Energy Used from Production: \" + \"{:.2f}\".format(evaluation_in.get_energy_used_from_pv()*2) + \" kWh\")\n",
    "print(\"Energy Not Used from Production: \" + \"{:.2f}\".format(evaluation_in.get_energy_not_used_from_pv()) + \" kWh\")\n",
    "print(\"Self Sufficiency (SS): \" + \"{:.2f}\".format(evaluation_in.get_self_sufficiency()*100) + \"%\")\n",
    "print(\"Self Consumption (SC): \" + \"{:.2f}\".format(evaluation_in.get_self_consumption()*100) + \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the metrics for the output\n",
    "evaluation_out = Evaluation(opt.iloc[:24*60], 0)\n",
    "\n",
    "print(\"Energy Used from Grid: \" + \"{:.2f}\".format(get_energy_used_from_grid(dfs)) + \" kWh\")\n",
    "print(\"Energy Used from Production: \" + \"{:.2f}\".format(get_energy_used_from_production(dfs)) + \" kWh\")\n",
    "print(\"Energy Not Used from Production: \" + \"{:.2f}\".format(get_energy_not_used_from_production(dfs)) + \" kWh\")\n",
    "print(\"Self Sufficiency (SS): \" + \"{:.2f}\".format(get_self_sufficiency(dfs)) + \"%\")\n",
    "print(\"Self Consumption (SC): \" + \"{:.2f}\".format(get_self_consumption(dfs)) + \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_timeslots_placement_graph_double(path, day):\n",
    "  abc = pd.read_csv(path + '/netload.csv', sep=';')\n",
    "  abc.columns = ['Date', 'Demand', 'PV_Production', 'Wind_Production', 'Production', 'Netload']\n",
    "  abc.drop('Netload', inplace=True, axis=1)\n",
    "  abc.drop('Demand', inplace=True, axis=1)\n",
    "  # abc.drop('Production', inplace=True, axis=1)\n",
    "\n",
    "  abc.set_index('Date')\n",
    "\n",
    "  tim2 = pd.read_csv(path + '/house0/WASHINGMACHINE.csv', sep=';')\n",
    "  # tim2['Power'] = tim2['Power'] + 62.1 * 30;\n",
    "  tim2 = tim2.rename(columns={\"Power\": \"Timeslot 2 - Washing Machine - House 1\"})\n",
    "  tim2.set_index('Date')\n",
    "\n",
    "  tim25 = pd.read_csv(path + '/house3/DISHWASHER.csv', sep=';')\n",
    "  # tim10['Power'] = tim10['Power'] + 62.1 * 30\n",
    "  tim25 = tim25.rename(columns={\"Power\": \"Timeslot 25 - Dishwasher - House 6\"})\n",
    "  tim25.set_index('Date')\n",
    "\n",
    "  tim33 = pd.read_csv(path + '/house4/WASHINGMACHINE.csv', sep=';')\n",
    "  # tim33['Power'] = tim33['Power'] + 62.1 * 30\n",
    "  tim33 = tim33.rename(columns={\"Power\": \"Timeslot 33 - Washing Machine - House 7\"})\n",
    "  tim33.set_index('Date')\n",
    "\n",
    "  df = pd.merge(pd.merge(pd.merge(abc, tim2, on='Date', how='left'), tim25, on='Date', how='left'), tim33, on='Date',\n",
    "                how='left')\n",
    "  df.set_index('Date')\n",
    "\n",
    "  df['Time'] = df['Date'].map(lambda x: datetime.datetime.strptime(str(x), \"%Y-%m-%d %H:%M:%S\").strftime(\"%H:%M\"))\n",
    "\n",
    "  fig, ax1 = plt.subplots()\n",
    "\n",
    "  ax1.set_xlabel('Time')\n",
    "  ax1.set_ylabel('Power (W)', color='red')\n",
    "  plt1 = ax1.plot(df['Time'][24*60*(day-1):24*60*day], df[\"Timeslot 2 - Washing Machine - House 1\"][24*60*(day-1):24*60*day], color='red',\n",
    "                  label='Timeslot 2 - Washing Machine - House 1')\n",
    "  plt2 = ax1.plot(df['Time'][24*60*(day-1):24*60*day], df[\"Timeslot 25 - Dishwasher - House 6\"][24*60*(day-1):24*60*day], color='green',\n",
    "                  label='Timeslot 25 - Dishwasher - House 6')\n",
    "  plt3 = ax1.plot(df['Time'][24*60*(day-1):24*60*day], df[\"Timeslot 33 - Washing Machine - House 7\"][24*60*(day-1):24*60*day], color='orange',\n",
    "                  label='Timeslot 33 - Washing Machine - House 7')\n",
    "  ax1.axis(ymin=-280, ymax=6000)\n",
    "  # ax1.set_xticks(df['Time'])\n",
    "  # ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "  # Adding Twin Axes\n",
    "\n",
    "  ax2 = ax1.twinx()\n",
    "\n",
    "  ax2.set_ylabel('Production (W)', color='blue')\n",
    "  plt4 = ax2.plot(df['Time'][24*60*(day-1):24*60*day], df[\"Production\"][24*60*(day-1):24*60*day], color='blue', label='Production')\n",
    "\n",
    "  # adds space between x values because there are a lot of different values for the x-axis and not all of them can be displayed\n",
    "  # ref. https://stackoverflow.com/questions/48251417/matplotlib-plots-multiple-dark-lines-on-x-axis\n",
    "  spacing = 200\n",
    "  visible = ax1.xaxis.get_ticklabels()[::spacing]\n",
    "  for label in ax1.xaxis.get_ticklabels():\n",
    "    if label not in visible:\n",
    "      label.set_visible(False)\n",
    "  visible = ax1.xaxis.get_ticklines()[::spacing]\n",
    "  for label in ax1.xaxis.get_ticklines():\n",
    "    if label not in visible:\n",
    "      label.set_visible(False)\n",
    "\n",
    "  # ax.get_xaxis().set_visible(False)\n",
    "  # Show plot\n",
    "\n",
    "  # join labels of both axis (ax1 and ax2)\n",
    "  plts = plt1 + plt2 + plt3 + plt4\n",
    "  labs = [l.get_label() for l in plts]\n",
    "  ax1.legend(plts, labs, loc=0)\n",
    "\n",
    "  plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for day in range(1, 7):\n",
    "  print(\"Day \" + str(day) + \":\")\n",
    "  show_timeslots_placement_graph_double(path_steps_minutes, day)\n",
    "  show_timeslots_placement_graph_double(path_steps_after_first, day)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}